{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from astroquery.mast import Observations, Catalogs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.table import Table, join, vstack\n",
    "from astropy.io import ascii\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Goals:\n",
    "- 1) gets/opens sector tic id lists\n",
    "- 2) downloads tic catalog based on tic ids (temp cuts, get ra/dec)\n",
    "- 3) uses ra/dec for mast query to get data urls\n",
    "- 4) creates shell script to download raw lc files \n",
    "\n",
    "- 5) merges/matches pipeline stats into tic catalog\n",
    "\n",
    "- 6) Download Vilanova Kepler EB catalog lcs\n",
    "\n",
    "### Warning: Before executing this notebook, download necessary data files (directions below) and change all placeholder 'Filepath' & 'filename' for your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique item finder\n",
    "\n",
    "def uniquefinder(mylist):\n",
    "    seen = {}\n",
    "    dupes = []\n",
    "    uniq_tics = []\n",
    "    for x in mylist:\n",
    "        if x not in seen:\n",
    "            seen[x] = 1\n",
    "            uniq_tics.append(x)\n",
    "        else:\n",
    "            if seen[x] == 1:\n",
    "                dupes.append(x)\n",
    "            seen[x] += 1\n",
    "    uniques = len(uniq_tics)\n",
    "    print('there are {} unique tics. Use the first output dictionary'.format(uniques), \\\n",
    "          'to see number of occurances for duplicates')\n",
    "    return seen, uniq_tics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://tess.mit.edu \n",
    "- under top menu item \"Observations\"-->\"Target Lists\" \n",
    "- download .csv file for desired sector(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open target list\n",
    "sector = 14 #enter relevant sector\n",
    "sector_file = pd.read_csv('Filepath/all_targets_S0{}_v1.csv'.format(sector),skiprows=5) #overlaps kepler\n",
    "sector_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull tic ids\n",
    "sector_ticids = sector_file['TICID'].to_numpy() #full sample\n",
    "len(sector_ticids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tic catalog to do teff cut prior to lc dl\n",
    "catalog_data_sector = Catalogs.query_criteria(catalog='Tic',ID=sector_ticids)\n",
    "#rename TIC ID column to match target name from Mast file for matching ease later\n",
    "catalog_data_sector.rename_column('ID', 'target_name')\n",
    "catalog_data_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do temp cut\n",
    "tempcut_sector = catalog_data_sector[catalog_data_sector['Teff']<6500]\n",
    "# pull tic ids after temp cut\n",
    "tics_tempcut = list(tempcut_sector['target_name']) #strings #cool stars only\n",
    "\n",
    "print('Sector-{} full sample size:{}, size after temp cut:{}'.format(sector,len(catalog_data_sector),len(tempcut_sector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine RA/DEC bounds for mast url query\n",
    "\n",
    "ra_sector = tempcut_sector['ra']\n",
    "dec_sector = tempcut_sector['dec']\n",
    "print('RA sector-{} (min/max):',min(ra_sector),max(ra_sector))\n",
    "print('DEC sector-{} (min/max):',min(dec_sector),max(dec_sector))\n",
    "\n",
    "#plot for confirmation\n",
    "plt.plot(ra_sector,dec_sector);plt.xlabel('RA');plt.ylabel('DEC');plt.title('Sector-{}'.format(sector));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\n",
    "- under top menu click 'Advanced Search'\n",
    "- query ra/dec bounds & check 'TESS' under 'Filters'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/mast_step1.png)\n",
    "![image](images/mast_step2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open mast file to get urls\n",
    "mast_file = pd.read_csv('Filepath/filename.csv',skiprows=4) #example filename: MAST_2020-08-06T2317\n",
    "print('Total number of mast files:',len(mast_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## match mast file with tempcut tic ids\n",
    "\n",
    "mastid = mast_file['target_name'].to_numpy()\n",
    "# convert types for merge\n",
    "tempcut_sector_df = tempcut_sector.to_pandas() #make table a df for joining\n",
    "# merge ---use this table in FOUR\n",
    "mast_ticcat_merge = pd.merge(tempcut_sector_df, mast_file, how='left', on='target_name') \n",
    "print('SEC-{} before merge:'.format(sector),len(tempcut_sector_df),' after merge:',len(mast_ticcat_merge),'targets')\n",
    "# test for how many unique tics merged\n",
    "dupes, uniques = uniquefinder(mast_ticcat_merge['target_name'].to_numpy())\n",
    "\n",
    "print('These two better match:', len(tempcut_sector_df),len(uniques))#'otherwise some targets have no lc datafiles')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create shell text strings from mast url's\n",
    "\n",
    "curlscript = []\n",
    "for i in range(len(mast_ticcat_merge)):\n",
    "    firststr = 'curl -C - -L -o '\n",
    "    middlestr = str(mast_ticcat_merge['obs_id'][i]) +'_lc.fits '\n",
    "    webaddy = \"https://mast.stsci.edu/api/v0.1/Download/file/?uri=\" \n",
    "    laststr = webaddy +str(mast_ticcat_merge['dataURL'][i])\n",
    "    script = firststr + middlestr + laststr \n",
    "    #print(script)\n",
    "    curlscript.append(script)\n",
    "curlscript=np.array(curlscript)\n",
    "curlscript.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SECTOR-15 create shell script (remove outter ''' ''' if need to rerun)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open ('Filepath/dl_sec{}.sh'.format(sector), 'w') as rsh:\n",
    "    for count,script in enumerate(curlscript):\n",
    "        rsh.write('''\\\n",
    "#! /bin/bash\n",
    "{}\n",
    "'''.format(script))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIVE\n",
    "###### *Requires all cells run up to section THREE & results file from 'run_LS.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/2\n",
    "#open data\n",
    "stats_sec = pd.read_csv('Filepath/ls_stats.csv'.format(sector)) #output from run_LS.py\n",
    "\n",
    "#prepare catalogs for merge\n",
    "tempcut_sector.rename_column('target_name','TIC') #change colname to match stats df\n",
    "stats_sec.insert(1, \"Sector\", np.repeat(sector,len(stats_sec)), True) #add sector so know where came from in final table\n",
    "stats_sec_table = Table.from_pandas(stats_sec) #change df to table to match tic catalog\n",
    "stats_sec_table['TIC'] =  stats_sec_table['TIC'].astype(str) #change datatype to match tic catalog\n",
    "\n",
    "# #do merge         \n",
    "result_sec = join(stats_sec_table, tempcut_sector, keys='TIC')\n",
    "# check result\n",
    "print(len(result_sec))\n",
    "result_sec[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2/2 -------already ran for sec15\n",
    "#save to file generalized for any ONE sector above\n",
    "ascii.write(result_sec,'Filepath/ls_ticcat_table.csv', format='csv',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to http://keplerebs.villanova.edu for Kepler Eclipsing Binary Catalog\n",
    "- choose 'File: comma-separated values\n",
    "- Click 'Download Catalog'\n",
    "- open file in a text editor and remove the # in front of column names line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/ebs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open EB files\n",
    "KeplerEB_file = pd.read_csv('Filepath/keplerebs.villanova.edu',header=7) #note if you changed the filename, change here as well\n",
    "# do cuts in period \n",
    "lower_period = .5\n",
    "upper_period = 15\n",
    "KeplerEB_periodcut = KeplerEB_file[(KeplerEB_file['period']>lower_period) &(KeplerEB_file['period']<upper_period)] # only periods within TESS easily measureable range\n",
    "\n",
    "print('column names:',list(KeplerEB_periodcut.columns))\n",
    "print('all EBs:',len(KeplerEB_file),'; EBs within {}-{} period range:'.format(lower_period,upper_period),len(KeplerEB_periodcut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads data\n",
    "\n",
    "# downloads every 3rd to get diverse sample (original table sorted by periods low-high)\n",
    "n = 3 #only dl every 3rd lc\n",
    "dl_count = 0\n",
    "for count,i in enumerate(list(KeplerEB_periodcut['KIC'])):\n",
    "    if count % n == 0: #remainder ==0 after division by interval\n",
    "        kic = i\n",
    "        url = 'http://keplerebs.villanova.edu/data/?k={}.00&cadence=lc&data=data'.format(kic)\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        filename = 'Filepath/{}_lc.csv'.format(kic)\n",
    "        open(filename, 'wb').write(r.content)\n",
    "        dl_count +=1\n",
    "    else:\n",
    "        pass\n",
    "print('Total files downloaded (.5< per <15):',dl_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
